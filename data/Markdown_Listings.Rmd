## RMarkdown dPREP project team 3: 'Which cities have the listings with the best value-for-money?'

### Variables dictionary (of our final generated dataset): 
New variable name | Definition    
------------------|----------------------------------------
id                | Airbnb's unique identifiier for the listing
list_name         | Name of the listing
host_id           | Airbnb's unique identifier for the host/user
neighbourhood     | Neighbourhood the listing is located
room_type         | Homes grouped as room types, incl. 'Entire place', 'Private room', 'Shared room', 'Entire place'
accommodates      | The maximum capacity of the listing
price             | Daily price of the listing in $
n_reviews         | Total number of reviews per listing
rev_rating        | Review score for rating 
rev_accuracy      | Review score for accuracy 
rev_clean         | Review score for cleanliness
rev_checkin       | Review score for checkin
rev_comm          | Review score for communication
rev_location      | Review score for location
rev_value         | Review score for value
n_reviews_month   | Number of reviews per listing per month 

### Step 0: Libraries
```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(readr)
```

### Step 1: Loading and inspecting the raw data

#### Loading the data from InsideAirbnb.com (only for Amsterdam here)
First, programmatically download the data from the Internet. 
```{r}
download.file('http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-08-06/data/listings.csv.gz', 'Listings.csv')
listings<-read.csv('Listings.csv')
head(listings)
```

### Step 2: Data transformation 
#### Dropping columns
We narrow down the dataset to what we like to focus on. 
```{r}
cols_to_keep <- c('id', 'name', 'host_id', 'neighbourhood_cleansed', 'room_type','accommodates', 'price','review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin','review_scores_communication', 'review_scores_location', 'review_scores_value','reviews_per_month','number_of_reviews')
price_quality_ratio<-listings[,which(colnames(listings)%in%cols_to_keep)]
head(price_quality_ratio) 
ncol(price_quality_ratio) #we retain only 16 columns
```
#### Renaming columns
Now we rename the columns that we kept for clarity. 
```{r}
price_quality_ratio <- price_quality_ratio %>%
  rename(neigbourhood = neighbourhood_cleansed,
         rev_accuracy = review_scores_accuracy,
         rev_comm = review_scores_communication,
         rev_clean = review_scores_cleanliness,
         rev_accuracy = review_scores_accuracy,
         rev_location = review_scores_location,
         rev_value = review_scores_value,
         rev_checkin = review_scores_checkin,
         rev_rating = review_scores_rating,
         n_reviews = number_of_reviews,
         n_reviews_month = reviews_per_month,
         list_name = name)
```

### Step 3: Cleaning the data
#### Checking and correcting variables' datatypes
```{r}
lapply(price_quality_ratio,class)
price_quality_ratio$list_name <- as.character(price_quality_ratio$list_name)
price_quality_ratio$price <- as.numeric(price_quality_ratio$price)
```
#### Filtering the bad observations (missings/0-values)
(maybe still filter for num_reviews>1 as 1 review wouldn't be representative of the listings' quality)
```{r}
cleaned_pq_ratio<-price_quality_ratio%>%filter(price != '$0.00') #removing listings with price=$0.00
cleaned_pq_ratio<-cleaned_pq_ratio%>%filter(n_reviews!=0) #removing listings with 0 reviews
```
All 7 categories of the review must be filled in (the value for one of the categories can't be 0.00. 
```{r}
cleaned_pq_ratio<-cleaned_pq_ratio%>%filter(rev_rating != 0.00, rev_clean !=0.00, rev_accuracy !=0.00, rev_comm !=0.00, rev_location !=0.00,rev_value !=0.00) #when rev_rating = 0.00, all other ratings for all other categories were NA so this data isn't useable -> now the review columns don't contain NA values anymore either. 
```
#### Checking range constraints
Ensuring that the star ratings do really fall between 1 and 5. 
```{r}
#for rev_rating (passed test)
breaks<-unique(c(min(cleaned_pq_ratio$rev_rating),1,5,max(cleaned_pq_ratio$rev_rating))) #wrapped with unique() to omit the error of 'breaks are not unique' message
ggplot(cleaned_pq_ratio,aes(rev_rating))+geom_histogram(breaks=breaks)
#for rev_accuracy (passed test)
breaks<-unique(c(min(cleaned_pq_ratio$rev_accuracy),1,5,max(cleaned_pq_ratio$rev_accuracy))) 
ggplot(cleaned_pq_ratio,aes(rev_accuracy))+geom_histogram(breaks=breaks)
#for rev_clean (passed test)
breaks<-unique(c(min(cleaned_pq_ratio$rev_clean),1,5,max(cleaned_pq_ratio$rev_clean))) 
ggplot(cleaned_pq_ratio,aes(rev_clean))+geom_histogram(breaks=breaks)
#for rev_checkin (passed test)
breaks<-unique(c(min(cleaned_pq_ratio$rev_checkin),1,5,max(cleaned_pq_ratio$rev_checkin))) 
ggplot(cleaned_pq_ratio,aes(rev_checkin))+geom_histogram(breaks=breaks)
#for rev_comm (passed test)
breaks<-unique(c(min(cleaned_pq_ratio$rev_comm),1,5,max(cleaned_pq_ratio$rev_comm))) 
ggplot(cleaned_pq_ratio,aes(rev_comm))+geom_histogram(breaks=breaks)
#for rev_location (passed test)
breaks<-unique(c(min(cleaned_pq_ratio$rev_location),1,5,max(cleaned_pq_ratio$rev_location))) 
ggplot(cleaned_pq_ratio,aes(rev_location))+geom_histogram(breaks=breaks)
#for rev_value (passed test)
breaks<-unique(c(min(cleaned_pq_ratio$rev_value),1,5,max(cleaned_pq_ratio$rev_value))) 
ggplot(cleaned_pq_ratio,aes(rev_value))+geom_histogram(breaks=breaks)
```

#### Checking uniqueness constraints  
Checking for full duplicates. 
```{r}
duplicated(cleaned_pq_ratio)
sum(duplicated(cleaned_pq_ratio)) #0 full duplicates (passed test)
```
Checking for partial duplicates. 
```{r}
cleaned_pq_ratio%>%count(id)%>%filter(n>1) #0 partial duplicates (passed test)
cleaned_pq_ratio%>%count(list_name,host_id,price)%>%filter(n>1) #some list names are the same (for n=22)
```
### Step 4: Data wrangling
#### Arranging, mutating, and summarizing 
```{r}
pq_ratio<-cleaned_pq_ratio%>%arrange(price) #arranged observations based on price
pq_ratio<-cleaned_pq_ratio%>%mutate(review = ((rev_rating+rev_accuracy+rev_clean+rev_checkin+rev_comm+rev_location+rev_value)/7)) #creates a new column for the average star rating based on the 7 categories
head(pq_ratio)
summary(pq_ratio)
meanreview_byprice<-pq_ratio%>%group_by(price)%>%summarize(meanRating=mean(review))  #creating a tibble with the average star rating (overall) for each price category
ggplot(meanreview_byprice,aes(x=price,y=meanRating))+geom_point() #there are very many categories so the plot doesn't look very clean
```

Plot for meanRating's above 4.   
```{r}
meanreviewhigh_byprice<-pq_ratio%>%group_by(price)%>%summarize(meanRating=mean(review))%>%filter(meanRating>4)
ggplot(meanreviewhigh_byprice,aes(x=price,y=meanRating))+geom_point()
``` 

Plot where we distinguish between different room types and how that differs in rating per price.  

```{r}
meanreview_bypriceroom<-pq_ratio%>%group_by(price,room_type)%>%summarize(meanRating=mean(review))
ggplot(meanreview_bypriceroom,aes(x=price,y=meanRating,color=room_type))+geom_point() #same problem with the price-axis still (needs fixing)
```


### Step 5: Data exploration   
Some summary statistics. 
```{r}
summary(pq_ratio)
overallrating_price<-pq_ratio%>%group_by(price)%>%summarize(mean_rating=mean(rev_rating)) #average overall rating per price class
pq_ratio%>%group_by(price)%>%summarize(mean_accuracy=mean(rev_accuracy),
                                               mean_comm=mean(rev_comm),
                                               mean_clean=mean(rev_clean),
                                               mean_location=mean(rev_location),
                                               mean_checkin=mean(rev_checkin),
                                               mean_value=mean(rev_value)) #average review scores per price class
```


